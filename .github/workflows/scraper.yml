# Call this whatever you want
name: scraper

# When does it get run?
on:
  # workflow_dispatch means "I can click a button and force it to run"
  workflow_dispatch:
  # schedule/cron means "on a set schedule"
  schedule:
    - cron: '*/5 * * * *'
jobs:
  scrape:
    # For some reason, we run love versions of linux
    runs-on: ubuntu-latest
    steps:
      # Download all of the code from your repo
      - name: Check out this repo
        uses: actions/checkout@v2
        with:
          fetch-depth: 0  # Fetch all history for proper git operations
      # Set up Python 3.10
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r automatic-scraper/requirements.txt
      # MAKE SURE YOUR SCRAPER FILENAME MATCHES THE FILENAME HERE!!
      - name: Run the scraping script
        run: |
          python automatic-scraper/scraper.py || exit 1
      # I just stole the rest of this code so don't ask me questions about it
      - name: Check for changes
        id: check_changes
        run: |
          if [[ -n $(git status --porcelain) ]]; then
            echo "Changes detected"
            echo "changes=true" >> $GITHUB_OUTPUT
          else
            echo "No changes detected"
            echo "changes=false" >> $GITHUB_OUTPUT
          fi
      - name: Commit and push if content changed
        if: steps.check_changes.outputs.changes
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          git add headlines.csv headlines.json
          timestamp=$(date -u)
          git commit -m "Update headlines: ${timestamp}"
          git push
